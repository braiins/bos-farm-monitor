# path: /etc/prometheus/prometheus.yml
# Global configuration.
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Scraping configuration.
scrape_configs:
  ## Prometheus can scrape itself to provide system statistics. Not needed, but recommended.
  - job_name: 'prometheus'
    static_configs:
    - targets: ['127.0.0.1:9090', 'nodeexporter:9100']

  # Automatic discovery job - this is suitable for automatically keeping a list of large
  # numbers of miners. See the file supercronic/scan_crontab on how to specify the IP
  # ranges to be scanned. Each scanned IP range produces a file. Its name is currently assigned
  # to label building dynamically.
  - job_name: 'braiinsos-data'
    metrics_path: '/metrics'
    scrape_interval: 5s
    file_sd_configs:
      - files:
        # read all files written by ssh_scan.sh
        - /mnt/miners_*.json
        refresh_interval: 15s
    relabel_configs:
      # Add file name as a label
      - source_labels: ["__meta_filepath"]
        regex: "\\/mnt\\/miners_(.+?)\\.json.*"
        target_label: "building"          
      # Get rid of port in address
      - source_labels: ["__address__"]
        regex: "^(.+?):.*"
        target_label: "instance"  
      ###################################################################################
      # The following is optional. Useful if you manage your farm by using
      # subnets.
      # Extract the site ID (second octet of IPv4 address)
      - source_labels: ["__address__"]
        regex: "\\d+\\.(\\d+)\\.\\d+\\.\\d+.*"
        target_label: "site_id"
      # Extract the subnet ID (third octet of IPv4 address)
      - source_labels: ["__address__"]
        regex: "\\d+\\.\\d+\\.(\\d+)\\.\\d+.*"
        target_label: "subnet_id"
      # Extract the host ID (last octet of IPv4 address)
      - source_labels: ["__address__"]
        regex: "\\d+\\.\\d+\\.\\d+\\.(\\d+).*"
        target_label: "host_id"
    metric_relabel_configs:
      ###################################################################################
      # Some of the detailed metrics are better removed. You can comment out / remove
      # the following section, however doing so will greatly increase the size needed to store
      # all the data. Make sure you really need these metrics and your storage size is
      # appropriate.
      - source_labels: [ __name__ ]
        regex: 'stratum_request_duration_bucket|stratum_request_duration_count|stratum_request_duration_sum'
        action: drop
      ###################################################################################
      # Temporary re-write of client_id into more useful labels
      # {connection_type, protocol, user, worker, host}
      - source_labels: [client_id]
        target_label: "host"
        regex: ".*@(.*)"
        action: "replace"
      - source_labels: [client_id]
        target_label: "connection_type"
        regex: "^(.+?):.*"
        action: "replace"
      - source_labels: [client_id]
        target_label: "worker"
        regex: ".*\\.(.+?)@.*"
        action: "replace"
      - source_labels: [client_id]
        target_label: "protocol"
        regex: "^.+?:(.*):.*"
        action: "replace"
      - source_labels: [client_id]
        target_label: "user"
        regex: ".*\\/\\/(.+?)[\\.@].*"
        action: "replace"
